–ù–∏–∂–µ ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π, –Ω–æ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π –ø—Ä–∏–º–µ—Ä novelty detection –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ scikit-learn, —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ —Ç–≤–æ–π –∫–µ–π—Å:
–∞–≤—Ç–æ—Ä –æ–±—ã—á–Ω–æ –ø–∏—à–µ—Ç –≤ —É–∑–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ ‚Üí –≤–Ω–µ–∑–∞–ø–Ω–æ –ø–æ—è–≤–ª—è–µ—Ç—Å—è —Ç–µ–∫—Å—Ç ‚Äú–∏–∑ –¥—Ä—É–≥–æ–π –æ–±–ª–∞—Å—Ç–∏‚Äù.
–Ø –ø–æ–∫–∞–∂—É –≤–∞—Ä–∏–∞–Ω—Ç —Å TF-IDF + One-Class SVM, –∞ –∑–∞—Ç–µ–º –∫—Ä–∞—Ç–∫–æ –ø–æ—è—Å–Ω—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã.
–ò–¥–µ—è –ø–æ–¥—Ö–æ–¥–∞
–û–±—É—á–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ ‚Äú–Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö‚Äù —Ç–µ–∫—Å—Ç–∞—Ö
(–ø–æ—Å—Ç—ã –ø—Ä–æ —á/–± –ø–ª—ë–Ω–æ—á–Ω—É—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é).
–ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç—ã –∫–∞–∫ –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (TF-IDF).
–£—á–∏–º –º–æ–¥–µ–ª—å novelty detection.
–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –ø–æ—Å—Ç—ã:
‚Üí inlier (–æ–±—ã—á–Ω–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞) –∏–ª–∏ outlier (–Ω–æ–≤–∏–∑–Ω–∞).
–ü—Ä–∏–º–µ—Ä: TF-IDF + One-Class SVM
1. –î–∞–Ω–Ω—ã–µ
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
train_texts = [
    "—á–µ—Ä–Ω–æ –±–µ–ª–∞—è –ø–ª–µ–Ω–æ—á–Ω–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è kodak tri-x",
    "–ø—Ä–æ—è–≤–∫–∞ –ø–ª–µ–Ω–∫–∏ ilford –≤ –¥–æ–º–∞—à–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö",
    "–∑–µ—Ä–Ω–æ –ø–ª–µ–Ω–∫–∏ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç —á–µ—Ä–Ω–æ –±–µ–ª—ã—Ö —Å–Ω–∏–º–∫–æ–≤",
    "–∞–Ω–∞–ª–æ–≥–æ–≤–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ö–∏–º–∏—á–µ—Å–∫–∞—è –ø—Ä–æ—è–≤–∫–∞"
]

test_texts = [
    "–ø–µ—á–∞—Ç—å —á–µ—Ä–Ω–æ –±–µ–ª—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ —Ñ–æ—Ç–æ–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏",
    "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ photoshop –∏ lightroom",
    "—Ü–∏—Ñ—Ä–æ–≤–∞—è —Ä–µ—Ç—É—à—å –∏ —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è"
]
2. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è + –º–æ–¥–µ–ª—å
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import OneClassSVM
from sklearn.pipeline import Pipeline
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
pipeline = Pipeline([
    ("tfidf", TfidfVectorizer(
        ngram_range=(1, 2),
        min_df=1,
        max_df=0.9
    )),
    ("ocsvm", OneClassSVM(
        kernel="rbf",
        gamma="scale",
        nu=0.1   # –æ–∂–∏–¥–∞–µ–º–∞—è –¥–æ–ª—è "–∞–Ω–æ–º–∞–ª–∏–π"
    ))
])
3. –û–±—É—á–µ–Ω–∏–µ (–¢–û–õ–¨–ö–û –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
pipeline.fit(train_texts)
4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
predictions = pipeline.predict(test_texts)
scores = pipeline.decision_function(test_texts)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
for text, pred, score in zip(test_texts, predictions, scores):
    label = "OK (–æ–±—ã—á–Ω–∞—è —Ç–µ–º–∞)" if pred == 1 else "NOVELTY (–∞–Ω–æ–º–∞–ª–∏—è)"
    print(f"{label:25} score={score:.3f} | {text}")
–¢–∏–ø–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥

OK (–æ–±—ã—á–Ω–∞—è —Ç–µ–º–∞)        score=0.12  | –ø–µ—á–∞—Ç—å —á–µ—Ä–Ω–æ –±–µ–ª—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π ...
NOVELTY (–∞–Ω–æ–º–∞–ª–∏—è)      score=-0.47 | –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ photoshop ...
NOVELTY (–∞–Ω–æ–º–∞–ª–∏—è)      score=-0.52 | —Ü–∏—Ñ—Ä–æ–≤–∞—è —Ä–µ—Ç—É—à—å –∏ —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è
–ü–æ—á–µ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
TF-IDF —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å –∞–≤—Ç–æ—Ä–∞
One-Class SVM —Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞–Ω–∏—Ü—É ‚Äú–Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏‚Äù
–¢–µ–∫—Å—Ç—ã —Å –∏–Ω—ã–º —Å–ª–æ–≤–∞—Ä—ë–º (photoshop, digital, retouch) –≤—ã–ø–∞–¥–∞—é—Ç
–ü–æ–ª–µ–∑–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
1. Isolation Forest (—á–∞—Å—Ç–æ –ø—Ä–æ—â–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
from sklearn.ensemble import IsolationForest
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
IsolationForest(
    n_estimators=200,
    contamination=0.1,
    random_state=42
)
–•–æ—Ä–æ—à –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤, –º–µ–Ω–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –º–∞—Å—à—Ç–∞–±—É.
2. Topic modeling + distance
LDA / NMF
–°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º
–ü–æ–¥—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –Ω–æ–≤–∏–∑–Ω–∞ = –ø–æ—è–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π —Ç–µ–º—ã, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–ª–æ–≤
3. Embeddings (Sentence-BERT) + novelty detection
–ì–æ—Ä–∞–∑–¥–æ —É—Å—Ç–æ–π—á–∏–≤–µ–µ –∫ —Å–∏–Ω–æ–Ω–∏–º–∞–º
–õ—É—á—à–µ –ø—Ä–∏ –Ω–µ–±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ç–µ–∫—Å—Ç–æ–≤
–ù–æ —É–∂–µ –Ω–µ ‚Äú—á–∏—Å—Ç—ã–π‚Äù sklearn
–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã
–û–±—É—á–∞–π—Å—è –Ω–∞ –æ–¥–Ω–æ–º –∞–≤—Ç–æ—Ä–µ, –∏–Ω–∞—á–µ ‚Äú—Å—Ç–∏–ª—å‚Äù —Å–º–µ—à–∞–µ—Ç—Å—è
–î–µ–ª–∞–π —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–±—É—á–µ–Ω–∏–µ (drift —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º)
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π decision_function, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ ¬±1
–£–±–∏—Ä–∞–π —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, —Ü–∏—Ñ—Ä—ã, –∏–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –≤ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ –º–æ–≥—É:
‚ú¶ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –ø—Ä–∏–º–µ—Ä –ø–æ–¥ IsolationForest
‚ú¶ –ø–æ–∫–∞–∑–∞—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç —Å SentenceTransformer
‚ú¶ –æ–±—Å—É–¥–∏—Ç—å, –∫–∞–∫ –æ—Ç–ª–∏—á–∞—Ç—å ‚Äú–Ω–æ–≤—É—é —Ç–µ–º—É‚Äù –æ—Ç ‚Äú–Ω–æ–≤–æ–π –ø–æ–¥-—Ç–µ–º—ã‚Äù






–ù–∏–∂–µ ‚Äî –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π –∏ ‚Äú–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π‚Äù –≤–∞—Ä–∏–∞–Ω—Ç novelty detection –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –±–∞–∑–µ
Sentence-BERT embeddings + –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è.
–≠—Ç–æ —Ä–µ—à–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É—Å—Ç–æ–π—á–∏–≤–µ–µ TF-IDF:
–Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è,
–ª–æ–≤–∏—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –Ω–æ–≤–∏–∑–Ω—É,
—Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ—Å—Ç–∞—Ö.
–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥

–¢–µ–∫—Å—Ç ‚Üí Sentence-BERT ‚Üí dense embedding ‚Üí novelty detection
–í –∫–∞—á–µ—Å—Ç–≤–µ novelty detector –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
One-Class SVM (—Å—Ç—Ä–æ–≥–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ ‚Äú–Ω–æ—Ä–º—ã‚Äù)
Isolation Forest (—á–∞—Å—Ç–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ)
–Ø –ø–æ–∫–∞–∂—É –æ–±–∞, –Ω–æ –Ω–∞—á–Ω—ë–º —Å –Ω–∞–∏–±–æ–ª–µ–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ.
1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Bash
pip install sentence-transformers scikit-learn
2. –î–∞–Ω–Ω—ã–µ
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
train_texts = [
    "—á–µ—Ä–Ω–æ –±–µ–ª–∞—è –ø–ª–µ–Ω–æ—á–Ω–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è kodak tri x",
    "–ø—Ä–æ—è–≤–∫–∞ –ø–ª–µ–Ω–∫–∏ ilford –∏ —Ñ–∏–∫—Å–∞–∂",
    "–∞–Ω–∞–ª–æ–≥–æ–≤–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –∑–µ—Ä–Ω–æ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç",
    "–ø–µ—á–∞—Ç—å —á–µ—Ä–Ω–æ –±–µ–ª—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ —Ñ–æ—Ç–æ–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏"
]

test_texts = [
    "–ø—Ä–æ—è–≤–∫–∞ —á–µ—Ä–Ω–æ –±–µ–ª–æ–π –ø–ª–µ–Ω–∫–∏ –¥–æ–º–∞",
    "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ photoshop –∏ lightroom",
    "—Ü–∏—Ñ—Ä–æ–≤–∞—è —Ä–µ—Ç—É—à—å –∏ —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π"
]
3. –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (Sentence-BERT)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
from sentence_transformers import SentenceTransformer
import numpy as np
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

X_train = model.encode(
    train_texts,
    normalize_embeddings=True
)

X_test = model.encode(
    test_texts,
    normalize_embeddings=True
)
–í–∞–∂–Ω–æ:
normalize_embeddings=True ‚Üí –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—è —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –µ–≤–∫–ª–∏–¥–æ–≤–æ–π
(—ç—Ç–æ —Å–∏–ª—å–Ω–æ —É–ø—Ä–æ—â–∞–µ—Ç –∂–∏–∑–Ω—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞–º).
4. –í–∞—Ä–∏–∞–Ω—Ç A: One-Class SVM
–û–±—É—á–µ–Ω–∏–µ
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
from sklearn.svm import OneClassSVM

ocsvm = OneClassSVM(
    kernel="rbf",
    gamma="scale",
    nu=0.1
)

ocsvm.fit(X_train)
–ü—Ä–æ–≤–µ—Ä–∫–∞
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
pred = ocsvm.predict(X_test)
scores = ocsvm.decision_function(X_test)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
for text, p, s in zip(test_texts, pred, scores):
    label = "OK (–Ω–æ—Ä–º–∞)" if p == 1 else "NOVELTY"
    print(f"{label:10} score={s:.3f} | {text}")
5. –í–∞—Ä–∏–∞–Ω—Ç B (—á–∞—Å—Ç–æ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ): Isolation Forest
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
from sklearn.ensemble import IsolationForest
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
iso = IsolationForest(
    n_estimators=300,
    contamination=0.1,
    random_state=42
)

iso.fit(X_train)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
pred = iso.predict(X_test)
scores = iso.decision_function(X_test)
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
for text, p, s in zip(test_texts, pred, scores):
    label = "OK (–Ω–æ—Ä–º–∞)" if p == 1 else "NOVELTY"
    print(f"{label:10} score={s:.3f} | {text}")
–ö–∞–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
prediction = -1 ‚Üí —Ç–µ–∫—Å—Ç –≤—ã–ø–∞–ª –∏–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–ª–∞–∫–∞
decision_function ‚Üí –º–µ—Ä–∞ ‚Äú—á—É–∂–µ—Ä–æ–¥–Ω–æ—Å—Ç–∏‚Äù
–º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –ø–æ—Ä–æ–≥ –≤—Ä—É—á–Ω—É—é, –∞ –Ω–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ contamination
–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ (—á–∞—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ)
–°—Ä–µ–¥–Ω—è—è –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è –¥–æ –∫–æ—Ä–ø—É—Å–∞
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
from sklearn.metrics.pairwise import cosine_distances

centroid = X_train.mean(axis=0)

distances = cosine_distances(X_test, centroid.reshape(1, -1)).ravel()
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Python
for text, d in zip(test_texts, distances):
    label = "NOVELTY" if d > 0.35 else "OK"
    print(f"{label:10} dist={d:.3f} | {text}")
‚úî –ü—Ä–æ–∑—Ä–∞—á–Ω–æ
‚úî –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ
‚úî –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è production-–∞–ª–µ—Ä—Ç–æ–≤
–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
–ú–æ–¥–µ–ª—å
paraphrase-multilingual-MiniLM-L12-v2 ‚Äî —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å
–¥–ª—è RU-only –º–æ–∂–Ω–æ –≤–∑—è—Ç—å ai-forever/sbert_large_nlu_ru
–û–±—É—á–µ–Ω–∏–µ
50‚Äì200 ‚Äú–Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö‚Äù —Ç–µ–∫—Å—Ç–æ–≤ ‚Äî —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
–æ–±–Ω–æ–≤–ª—è–π –º–æ–¥–µ–ª—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (topic drift)
–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –ß–¢–û –∏–º–µ–Ω–Ω–æ?
–°—Ü–µ–Ω–∞—Ä–∏–π
–ú–µ—Ç–æ–¥
–†–µ–∑–∫–æ –Ω–æ–≤–∞—è —Ç–µ–º–∞
IsolationForest
–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–π —Å–¥–≤–∏–≥
distance to centroid
–ñ—ë—Å—Ç–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å —Ç–µ–º–∞—Ç–∏–∫–∏
One-Class SVM
–ö–æ–≥–¥–∞ —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —Ö–æ—Ä–æ—à
–ê–≤—Ç–æ—Ä ‚Üí –æ–¥–∏–Ω —Å—Ç–∏–ª—å –º—ã—à–ª–µ–Ω–∏—è
–ù–æ–≤–∏–∑–Ω–∞ = —Å–º–µ–Ω–∞ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤, –∞ –Ω–µ —Å–ª–æ–≤
–ö–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã (–ø–æ—Å—Ç—ã, –∑–∞–º–µ—Ç–∫–∏)







import time
import functools
from datetime import datetime, timedelta


def seconds_until_next_retry(now: datetime) -> int:
    weekday = now.weekday()  # 0 = Monday, 5 = Saturday, 6 = Sunday

    # –±—É–¥–Ω–∏–π –¥–µ–Ω—å –∏ —Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è 09:00‚Äì17:00
    if weekday < 5 and 9 <= now.hour < 17:
        return 30 * 60  # 30 –º–∏–Ω—É—Ç

    # –∏–Ω–∞—á–µ ‚Äî –∂–¥–∞—Ç—å –¥–æ 10:00 –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞
    days_ahead = (7 - weekday) % 7
    if days_ahead == 0:
        days_ahead = 7

    next_monday = (now + timedelta(days=days_ahead)).replace(
        hour=10, minute=0, second=0, microsecond=0
    )

    return int((next_monday - now).total_seconds())


def retry_with_wait(max_attempts: int):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            attempt = 1
            while True:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt >= max_attempts:
                        raise

                    now = datetime.now()
                    wait_seconds = seconds_until_next_retry(now)

                    print(
                        f"–ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}. "
                        f"–°–ª–µ–¥—É—é—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {wait_seconds // 60} –º–∏–Ω—É—Ç."
                    )

                    time.sleep(wait_seconds)
                    attempt += 1

        return wrapper
    return decorator
    
    
    
    usage

    
@retry_with_wait(max_attempts=5)
def unstable_job():
    print("–í—ã–ø–æ–ª–Ω—è—é –∑–∞–¥–∞—á—É...")
    raise RuntimeError("–í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞")


    



pip install statsmodels pandas numpy matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.api import SimpleExpSmoothing, Holt
import warnings
warnings.filterwarnings('ignore')

# –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
data = [13, 10, 7, 17, 5, 13, 3, 9, 2, 7, 5, 6, 1, 0, 3]

# –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —ç—Ç–æ 15 –º–µ—Å—è—Ü–µ–≤ –ø–æ–¥—Ä—è–¥)
dates = pd.date_range(start='2023-01-01', periods=len(data), freq='M')
ts = pd.Series(data, index=dates)

print("–ò—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥:")
print(ts)
print(f"\n–î–ª–∏–Ω–∞ —Ä—è–¥–∞: {len(ts)} –º–µ—Å—è—Ü–µ–≤")

# –ú–µ—Ç–æ–¥ 1: –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ (–ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞)
window_size = 3  # —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
ts_trend_ma = ts.rolling(window=window_size, center=True, min_periods=1).mean()

# –ú–µ—Ç–æ–¥ 2: –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
model_ses = SimpleExpSmoothing(ts).fit(smoothing_level=0.3)
ts_trend_ses = model_ses.fittedvalues

# –ú–µ—Ç–æ–¥ 3: –ú–æ–¥–µ–ª—å –•–æ–ª—Ç–∞ (–¥–≤–æ–π–Ω–æ–µ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ) –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
model_holt = Holt(ts).fit(smoothing_level=0.3, smoothing_trend=0.1)
ts_trend_holt = model_holt.fittedvalues

# –ú–µ—Ç–æ–¥ 4: –õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ —á–µ—Ä–µ–∑ —Ä–µ–≥—Ä–µ—Å—Å–∏—é (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥)
# –°–æ–∑–¥–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏
X = np.arange(len(ts)).reshape(-1, 1)
y = ts.values

from sklearn.linear_model import LinearRegression
model_lr = LinearRegression()
model_lr.fit(X, y)
linear_trend = model_lr.predict(X)

# –ú–µ—Ç–æ–¥ 5: –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å)
# –î–ª—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ä—è–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–¥–∏—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å
try:
    decomposition = seasonal_decompose(ts, model='additive', period=3)  # period - –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
    trend_decompose = decomposition.trend
except:
    trend_decompose = None
    print("\n–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π –¥–ª—è —Ç–∞–∫–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ä—è–¥–∞")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π', fontsize=16)

# –ò—Å—Ö–æ–¥–Ω—ã–π —Ä—è–¥
axes[0, 0].plot(ts, marker='o', label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
axes[0, 0].plot(ts_trend_ma, color='red', linewidth=2, label=f'–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ (–æ–∫–Ω–æ={window_size})')
axes[0, 0].set_title('–ú–µ—Ç–æ–¥ 1: –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ')
axes[0, 0].set_xlabel('–ú–µ—Å—è—Ü')
axes[0, 0].set_ylabel('–ß–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π')
axes[0, 0].legend()
axes[0, 0].grid(True)

# –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
axes[0, 1].plot(ts, marker='o', label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
axes[0, 1].plot(ts_trend_ses, color='green', linewidth=2, label='–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ')
axes[0, 1].set_title('–ú–µ—Ç–æ–¥ 2: –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ')
axes[0, 1].set_xlabel('–ú–µ—Å—è—Ü')
axes[0, 1].set_ylabel('–ß–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π')
axes[0, 1].legend()
axes[0, 1].grid(True)

# –ú–æ–¥–µ–ª—å –•–æ–ª—Ç–∞ –∏ –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥
axes[1, 0].plot(ts, marker='o', label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
axes[1, 0].plot(ts_trend_holt, color='purple', linewidth=2, label='–ú–æ–¥–µ–ª—å –•–æ–ª—Ç–∞')
axes[1, 0].plot(ts.index, linear_trend, color='orange', linestyle='--', linewidth=2, label='–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥')
axes[1, 0].set_title('–ú–µ—Ç–æ–¥ 3: –ú–æ–¥–µ–ª—å –•–æ–ª—Ç–∞ –∏ –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥')
axes[1, 0].set_xlabel('–ú–µ—Å—è—Ü')
axes[1, 0].set_ylabel('–ß–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π')
axes[1, 0].legend()
axes[1, 0].grid(True)

# –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
if trend_decompose is not None:
    axes[1, 1].plot(ts, marker='o', alpha=0.5, label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    axes[1, 1].plot(trend_decompose, color='brown', linewidth=3, label='–¢—Ä–µ–Ω–¥ (–¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è)')
    axes[1, 1].set_title('–ú–µ—Ç–æ–¥ 4: –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞')
    axes[1, 1].set_xlabel('–ú–µ—Å—è—Ü')
    axes[1, 1].set_ylabel('–ß–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π')
else:
    axes[1, 1].text(0.5, 0.5, '–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\n(—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ä—è–¥)', 
                    ha='center', va='center', transform=axes[1, 1].transAxes)
    axes[1, 1].set_title('–ú–µ—Ç–æ–¥ 4: –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞')
axes[1, 1].legend()
axes[1, 1].grid(True)

plt.tight_layout()
plt.show()

# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("\n" + "="*60)
print("–ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–ê:")
print("="*60)

# –ê–Ω–∞–ª–∏–∑ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞
print(f"\n1. –õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥:")
print(f"   –£—Ä–∞–≤–Ω–µ–Ω–∏–µ: y = {model_lr.intercept_:.2f} + {model_lr.coef_[0]:.2f} * t")
print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –Ω–∞–∫–ª–æ–Ω–∞: {model_lr.coef_[0]:.2f}")

if model_lr.coef_[0] > 0:
    print("   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –°–†–ï–î–ù–ò–ô –†–û–°–¢ —á–∏—Å–ª–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π")
elif model_lr.coef_[0] < 0:
    print("   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –°–†–ï–î–ù–ï–ï –°–ù–ò–ñ–ï–ù–ò–ï —á–∏—Å–ª–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π")
else:
    print("   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: —Ç—Ä–µ–Ω–¥ –û–¢–°–£–¢–°–¢–í–£–ï–¢")

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞
print(f"\n2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞:")
print(f"   –°—Ä–µ–¥–Ω–µ–µ –∑–∞ –ø–µ—Ä–≤—ã–µ 3 –º–µ—Å—è—Ü–∞: {np.mean(data[:3]):.1f}")
print(f"   –°—Ä–µ–¥–Ω–µ–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞: {np.mean(data[-3:]):.1f}")

change = ((np.mean(data[-3:]) - np.mean(data[:3])) / np.mean(data[:3])) * 100
print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {change:.1f}%")

if change > 10:
    print("   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–´–ô –†–û–°–¢")
elif change < -10:
    print("   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–û–ï –°–ù–ò–ñ–ï–ù–ò–ï")
else:
    print("   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø –°–ò–¢–£–ê–¶–ò–Ø (–±–µ–∑ —Ä–µ–∑–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π)")

# –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥
print(f"\n3. –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –º–µ—Å—è—Ü (–ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å):")
next_month = len(ts)
forecast = model_lr.predict([[next_month]])[0]
print(f"   –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–æ–µ —á–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {forecast:.1f}")
print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: [{max(0, forecast-5):.1f}, {forecast+5:.1f}]")

# –û–±—â–∏–π –≤—ã–≤–æ–¥
print(f"\n4. –û–ë–©–ò–ô –í–´–í–û–î:")
if model_lr.coef_[0] < -0.5 and change < -20:
    print("   üìâ –ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è –Ø–í–ù–ê–Ø –ù–ò–°–•–û–î–Ø–©–ê–Ø –¢–ï–ù–î–ï–ù–¶–ò–Ø")
elif model_lr.coef_[0] > 0.5 and change > 20:
    print("   üìà –ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è –Ø–í–ù–ê–Ø –í–û–°–•–û–î–Ø–©–ê–Ø –¢–ï–ù–î–ï–ù–¶–ò–Ø")
else:
    print("   üìä –¢—Ä–µ–Ω–¥ –ù–ï–Ø–í–ù–´–ô –∏–ª–∏ –û–¢–°–£–¢–°–¢–í–£–ï–¢. –ö–æ–ª–µ–±–∞–Ω–∏—è –Ω–æ—Å—è—Ç —Å–ª—É—á–∞–π–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä.")




    

–í–∞—Ä–∏–∞–Ω—Ç 2 ‚Äî Git —á–µ—Ä–µ–∑ —Å–µ—Ç–µ–≤—É—é —à–∞—Ä—É (SMB)
–ï—Å–ª–∏ SSH ‚Äî —ç—Ç–æ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ, –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —à–∞—Ä–∏—Ç—å –ø–∞–ø–∫—É —Å bare-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏ —á–µ—Ä–µ–∑ –æ–±—ã—á–Ω—É—é —Å–µ—Ç–µ–≤—É—é —à–∞—Ä—É Windows.
–®–∞–≥–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
–°–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É C:\git_repos.
–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–µ—Ç–µ–≤—É—é —à–∞—Ä—É (Properties ‚Üí Sharing).
–î–∞—Ç—å –ø—Ä–∞–≤–∞ –Ω–∞ —á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å –Ω—É–∂–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º.
–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å bare-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∫–∞–∫ –≤—ã—à–µ:
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Powershell
cd C:\git_repos
git init --bare myproject.git
–ù–∞ —Ä–∞–±–æ—á–∏—Ö —Å—Ç–∞–Ω—Ü–∏—è—Ö
–°–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —à–∞—Ä—É –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å UNC-–ø—É—Ç—å:
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Bash
git clone //SERVER_NAME/git_repos/myproject.git
–∏–ª–∏ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ –¥–∏—Å–∫:
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
Bash
net use G: \\SERVER_NAME\git_repos
git clone G:/myproject.git
‚ö†Ô∏è –ú–∏–Ω—É—Å: –Ω–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Git, –Ω–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏ —ç—Ç–æ —á–∞—Å—Ç–æ –ø—Ä–∏–µ–º–ª–µ–º–æ.

# Blogicum
Blogicum - —Å–µ—Ä–≤–∏—Å –≤–µ–¥–µ–Ω–∏—è –ª–∏—á–Ω—ã—Ö –±–ª–æ–≥–æ–≤.
–£—á–µ–±–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Å –ø—Ä–∏–º–µ—Ä–æ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ API-—Ñ—É–Ω–∫—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ DRF 
–¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤.

## –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
[Django](https://www.djangoproject.com/),
[Django REST framework](https://www.django-rest-framework.org/)

## –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –∑–∞–ø—É—Å–∫—É –ø—Ä–æ–µ–∫—Ç–∞
–ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ –ø–µ—Ä–µ–π—Ç–∏ –≤ –Ω–µ–≥–æ –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ:

```
git clone https://github.com/oleg-zharkikh/blogicum-drf
```

```
cd blogicum-drf
```
–°–æ–∑–¥–∞—Ç—å –∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ;
Windows
```
python -m venv venv
source venv/Scripts/activate
```
Linux/macOS
```
python3 -m venv venv
source venv/bin/activate
```

–û–±–Ω–æ–≤–∏—Ç—å PIP:

Windows
```
python -m pip install --upgrade pip
```
Linux/macOS
```
python3 -m pip install --upgrade pip
```

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ —Ñ–∞–π–ª–∞ requirements.txt:

```
pip install -r requirements.txt
```

–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–µ–∫—Ç:

Windows
```
python blogicum/manage.py runserver
```

Linux/macOS
```
python3 blogicum/manage.py runserver
```
